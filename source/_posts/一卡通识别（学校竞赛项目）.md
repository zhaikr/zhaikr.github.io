---
title: 一卡通识别（学校竞赛项目）
author: JackRay
date: 2018-11-23 19:02:00
cateogries: 图像识别
tag: [python,图像识别,pytesseract]
---

因为在学校有人找到我一起去打比赛，那我就去了。我们做的是将我们学校的一卡通上的学号识别出来。

![20181028_161604](一卡通识别（学校竞赛项目）\20181028_161604.jpg)

上图就是我们学校的一卡通要将学号给识别出来。

首先我的想法就是先找到特征点然后根据特征点的位置来确定学号的位置，然后再将学号给切割出来，这样的话就可以识别学号了。

首先我定义一个函数

如下：

```python
def shibie(img):    
    image_arr = np.array(img)将图片变为矩阵
    y_fd,x_fd = img.shape[:2]切出前两个参数
    for y in range(y_fd):
        for x in range(x_fd):
            pj = image_arr[y,x]
            a = pj[0]
            b = pj[1]
            c = pj[2]
            if a <= 1735 and a >= 158:    #调节参数 寻找特征点参数 
                if b <= 185 and b >= 175:
                    if c <= 105 and c >= 90:
                        y_list.append(y)
                        x_list.append(x)
```

我的特征是根据图片的颜色通道来进行查找的，我找的特征点是学生卡那一块，因为那块的绿色比较容易找到不会出特别大的误差，就是有时候会不同设备拍摄出的照片的颜色(RBG)会不同导致参数可能不是特别准确，会匹配到其他位置去。

我又定义一个函数进行判断

如下：

```python
def panduan(i,j,m,n,img):   #获取特征区域x,y最大值和最小值
    x_board = i-j
    y_board = m-n
    if x_board > y_board:    #判断图片的方向如果相反 进行图片旋转
        img = Image.open(lujing)
        img = img.rotate(270, expand=True)
        img.save(lujing)
        img = plt.imread(lujing)
        x_list.clear
        y_list.clear
        shibie(img)
        xmax = max(x_list)
        xmin = min(x_list)
        ymax = max(y_list)
        ymin = min(y_list)
        return xmax,xmin,ymax,ymin
```

这里写了一个小小的判断，其中因为有的人拍照可能是横着拍，有的人是竖着拍的就会造成后面我们无法切割学号所以需要我们判断图片方向，然后我们要取出这个区域x,y的max,min。

最后就是执行程序，进行学号切割识别

如下：

```Python
def xuehaoshibie(img):
    shibie(img)
    xmax = max(x_list)
    xmin = min(x_list)
    ymax = max(y_list)
    ymin = min(y_list)
    panduan(xmax,xmin,ymax,ymin,img)
    bili = (xmax-xmin)//365  #图片的矩阵比例
    if bili == 0:
        bili = 1
    y_tezheng = (ymax+ymin)//2
    x_xhmax = xmin - 220*bili
    x_xhmin = xmin - 550*bili
    y_xhmin = ymin - 750*bili
    y_xhmax = y_tezheng
    im = img[y_xhmin:y_xhmax,x_xhmin:x_xhmax,:]
    shibiexuehao = pytesseract.image_to_string(im)
    b = re.compile('\d+')
    data = b.findall(shibiexuehao)[0]
    print(data)
    return data
```

这里因为不同照片一卡通距离也会不同，但是一卡通这个本体不会改变我们只要找到一个比例然后根据比例来对将一卡通学号那一块区域切割下来。

这里我们首先根据特征区域的大小来确定比例，然后就在图像矩阵上查找就能切割图片。

最后用调用识别库来识别学号就行了。

我的github上也有完整代码：https://github.com/zhaikr/yikatongshibie
